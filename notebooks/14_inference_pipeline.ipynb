{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_date=Timestamp('2023-06-13 06:00:00')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "current_date = pd.to_datetime(datetime.utcnow()).floor('H') # - timedelta(hours=1)\n",
    "print(f'{current_date=}')\n",
    "# current_date = pd.Timestamp('2023-02-28 09:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/45258\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Fetching data from 2023-05-16 06:00:00 to 2023-06-13 05:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: No training dataset version was provided to initialise batch scoring . Defaulting to version 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-13 07:09:19,159 INFO: USE `taxi_demand_se_featurestore`\n",
      "2023-06-13 07:09:19,891 INFO: SELECT `fg0`.`pickup_hour` `pickup_hour`, `fg0`.`rides` `rides`, `fg0`.`pickup_location_id` `pickup_location_id`\n",
      "FROM `taxi_demand_se_featurestore`.`time_series_hourly_feature_group_1` `fg0`\n",
      "WHERE `fg0`.`pickup_hour` >= TIMESTAMP '2023-05-15 06:00:00.000' AND `fg0`.`pickup_hour` <= TIMESTAMP '2023-06-14 05:00:00.000'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Time-series data is not complete. Make sure your feature pipeline is up and runnning.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minference\u001b[39;00m \u001b[39mimport\u001b[39;00m load_batch_of_features_from_store\n\u001b[1;32m----> 3\u001b[0m features \u001b[39m=\u001b[39m load_batch_of_features_from_store(current_date)\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Ai Portfolio Projects\\taxi_demand_predictor-main\\src\\inference.py:71\u001b[0m, in \u001b[0;36mload_batch_of_features_from_store\u001b[1;34m(current_date)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39m# validate we are not missing data in the feature store\u001b[39;00m\n\u001b[0;32m     70\u001b[0m location_ids \u001b[39m=\u001b[39m ts_data[\u001b[39m'\u001b[39m\u001b[39mpickup_location_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[1;32m---> 71\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(ts_data) \u001b[39m==\u001b[39m n_features\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(location_ids), \\\n\u001b[0;32m     72\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mTime-series data is not complete. Make sure your feature pipeline is up and runnning.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[39m# sort data by location and time\u001b[39;00m\n\u001b[0;32m     75\u001b[0m ts_data\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mpickup_location_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpickup_hour\u001b[39m\u001b[39m'\u001b[39m], inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Time-series data is not complete. Make sure your feature pipeline is up and runnning."
     ]
    }
   ],
   "source": [
    "from src.inference import load_batch_of_features_from_store\n",
    "\n",
    "features = load_batch_of_features_from_store(current_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference import (\n",
    "    load_model_from_registry,\n",
    "    get_model_predictions\n",
    ")\n",
    "\n",
    "model = load_model_from_registry()\n",
    "predictions = get_model_predictions(model, features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['pickup_hour'] = current_date\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_store_api import get_feature_store\n",
    "import src.config as config\n",
    "\n",
    "# connect to the feature group\n",
    "feature_group = get_feature_store().get_or_create_feature_group(\n",
    "    name=config.FEATURE_GROUP_MODEL_PREDICTIONS,\n",
    "    version=1,\n",
    "    description=\"Predictions generate by our production model\",\n",
    "    primary_key = ['pickup_location_id', 'pickup_hour'],\n",
    "    event_time='pickup_hour',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group.insert(predictions, write_options={\"wait_for_job\": False})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
